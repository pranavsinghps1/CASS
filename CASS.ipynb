{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import timm\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms as tsfm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torchcontrib.optim import SWA\n",
    "from torchmetrics import Metric\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_path = '/scratch/ISIC2019/train/isic_train.csv'\n",
    "    train_imgs_dir = '/scratch/ISIC2019/train/'\n",
    "    # model info\n",
    "    # label info\n",
    "    label_num2str = {0: 'NV',\n",
    "                     1: 'MEL',\n",
    "                     2: 'BCC',\n",
    "                     3: 'BKL',\n",
    "                     4: 'AK',\n",
    "                     5: 'SCC',\n",
    "                     6: 'VASC',\n",
    "                     7: 'DF'\n",
    "                     }\n",
    "    label_str2num = {'NV': 0,\n",
    "                     'MEL':1,\n",
    "                     'BCC':2,\n",
    "                     'BKL':3,\n",
    "                     'AK':4,\n",
    "                     'SCC':5,\n",
    "                     'VASC':6,\n",
    "                     'DF':7 \n",
    "                     }\n",
    "    fl_alpha = 1.0  # alpha of focal_loss\n",
    "    fl_gamma = 2.0  # gamma of focal_loss\n",
    "    cls_weight = [1.0, 0.4717294571343815, 0.39523385741125283, 0.3535449421536636, 0.2405023237417186, 0.2242064669237615, 0.20134480371798677, 0.2]\n",
    "    cnn_name='resnet50'\n",
    "    vit_name='vit_base_patch16_384'\n",
    "    seed = 77\n",
    "    num_classes = 8\n",
    "    batch_size = 16\n",
    "    t_max = 16\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    n_fold = 6\n",
    "    num_workers = 8\n",
    "    accum_grad_batch = 1\n",
    "    early_stop_delta = 1e-7\n",
    "    gpu_idx = 0\n",
    "    device = torch.device(f'cuda:{gpu_idx}' if torch.cuda.is_available() else 'cpu')\n",
    "    gpu_list = [gpu_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_everything(77)\n",
    "cfg=CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define train & valid image transformation\n",
    "\"\"\"\n",
    "DATASET_IMAGE_MEAN = (0.485, 0.456, 0.406)\n",
    "DATASET_IMAGE_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = tsfm.Compose([tsfm.Resize((384,384)),\n",
    "                                tsfm.RandomApply([tsfm.ColorJitter(0.2, 0.2, 0.2),tsfm.RandomPerspective(distortion_scale=0.2),], p=0.3),\n",
    "                                tsfm.RandomApply([tsfm.ColorJitter(0.2, 0.2, 0.2),tsfm.RandomAffine(degrees=10),], p=0.3),\n",
    "                                tsfm.RandomVerticalFlip(p=0.3),\n",
    "                                tsfm.RandomHorizontalFlip(p=0.3),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])\n",
    "\n",
    "valid_transform = tsfm.Compose([tsfm.Resize((384,384)),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define dataset class\n",
    "\"\"\"\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, cfg, img_names: list, labels: list, transform=None):\n",
    "        self.img_dir = cfg.train_imgs_dir\n",
    "        self.img_names = img_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx]+'.jpg')\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_ts = self.transform(img)\n",
    "        label_ts = self.labels[idx]\n",
    "        return img_ts, label_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Focal-Loss\n",
    "\"\"\"\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    The focal loss for fighting against class-imbalance\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = 1e-12  # prevent training from Nan-loss error\n",
    "        self.cls_weights = torch.tensor([CFG.cls_weight],dtype=torch.float, requires_grad=False, device=CFG.device)\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits & target should be tensors with shape [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(logits)\n",
    "        one_subtract_probs = 1.0 - probs\n",
    "        # add epsilon\n",
    "        probs_new = probs + self.epsilon\n",
    "        one_subtract_probs_new = one_subtract_probs + self.epsilon\n",
    "        # calculate focal loss\n",
    "        log_pt = target * torch.log(probs_new) + (1.0 - target) * torch.log(one_subtract_probs_new)\n",
    "        pt = torch.exp(log_pt)\n",
    "        focal_loss = -1.0 * (self.alpha * (1 - pt) ** self.gamma) * log_pt\n",
    "        focal_loss = focal_loss * self.cls_weights\n",
    "        return torch.mean(focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define F1 score metric\n",
    "\"\"\"\n",
    "class MyF1Score(Metric):\n",
    "    def __init__(self, cfg, threshold: float = 0.5, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.cfg = cfg\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"tp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fn\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        assert preds.shape == target.shape\n",
    "        preds_str_batch = self.num_to_str(torch.sigmoid(preds))\n",
    "        target_str_batch = self.num_to_str(target)\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for pred_str_list, target_str_list in zip(preds_str_batch, target_str_batch):\n",
    "            for pred_str in pred_str_list:\n",
    "                if pred_str in target_str_list:\n",
    "                    tp += 1\n",
    "                if pred_str not in target_str_list:\n",
    "                    fp += 1\n",
    "\n",
    "            for target_str in target_str_list:\n",
    "                if target_str not in pred_str_list:\n",
    "                    fn += 1\n",
    "        self.tp += tp\n",
    "        self.fp += fp\n",
    "        self.fn += fn\n",
    "\n",
    "    def compute(self):\n",
    "        #To switch between F1 score and recall.\n",
    "        #f1 = 2.0 * self.tp / (2.0 * self.tp + self.fn + self.fp)\n",
    "        rec = self.tp/(self.tp + self.fn)\n",
    "        return rec\n",
    "    \n",
    "    def num_to_str(self, ts: torch.Tensor) -> list:\n",
    "        batch_bool_list = (ts > self.threshold).detach().cpu().numpy().tolist()\n",
    "        batch_str_list = []\n",
    "        for one_sample_bool in batch_bool_list:\n",
    "            lb_str_list = [self.cfg.label_num2str[lb_idx] for lb_idx, bool_val in enumerate(one_sample_bool) if bool_val]\n",
    "            batch_str_list.append(lb_str_list)\n",
    "        return batch_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(cfg.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['image_name'], df['diagnosis'], test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_names: list = X_train.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_names_valid: list = X_val.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_labels_ts = []\n",
    "for tmp_lb in y_train:\n",
    "    tmp_label = torch.zeros([CFG.num_classes], dtype=torch.float)\n",
    "    label_num=CFG.label_str2num.get(tmp_lb)\n",
    "    k=int(label_num)\n",
    "    tmp_label[k] = 1.0\n",
    "    all_img_labels_ts.append(tmp_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_labels_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_labels_val_ts = []\n",
    "for tmp_lb in y_val:\n",
    "    tmp_label = torch.zeros([CFG.num_classes], dtype=torch.float)\n",
    "    label_num=CFG.label_str2num.get(tmp_lb)\n",
    "    k=int(label_num)\n",
    "    tmp_label[k] = 1.0\n",
    "    all_img_labels_val_ts.append(tmp_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_labels_val_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = timm.create_model(cfg.cnn_name, pretrained=True)\n",
    "model_vit = timm.create_model(cfg.vit_name, pretrained=True)\n",
    "model_cnn.to(device)\n",
    "model_vit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssl_train_model(train_loader,model_vit,criterion_vit,optimizer_vit,scheduler_vit,model_cnn,criterion_cnn,optimizer_cnn,scheduler_cnn,num_epochs):\n",
    "    writer = SummaryWriter()\n",
    "    phase = 'train'\n",
    "    model_cnn.train()\n",
    "    model_vit.train()\n",
    "    f1_score_cnn=0\n",
    "    f1_score_vit=0\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            for img,_ in train_loader:\n",
    "                f1_score_cnn=0\n",
    "                f1_score_vit=0\n",
    "                img = img.to(device)\n",
    "                pred_vit = model_vit(img)\n",
    "                pred_cnn = model_cnn(img)\n",
    "                model_sim_loss=loss_fn(pred_vit,pred_cnn)\n",
    "                loss = model_sim_loss.mean()\n",
    "                loss.backward()\n",
    "                optimizer_cnn.step()\n",
    "                optimizer_vit.step()\n",
    "                scheduler_cnn.step()\n",
    "                scheduler_vit.step()\n",
    "            print('For -',i,'Loss:',loss) \n",
    "            writer.add_scalar(\"Self-Supervised Loss/train\", loss, i)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cnn = SWA(torch.optim.Adam(model_cnn.parameters(), lr= 1e-3))\n",
    "optimizer_vit = SWA(torch.optim.Adam(model_vit.parameters(), lr= 1e-3))\n",
    "scheduler_cnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_cnn,\n",
    "                                                                    T_max=16,\n",
    "                                                                    eta_min=1e-6)\n",
    "scheduler_vit = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_vit,\n",
    "                                                                    T_max=16,\n",
    "                                                                    eta_min=1e-6)\n",
    "\n",
    "criterion_vit = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)\n",
    "criterion_cnn = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    x =  torch.nn.functional.normalize(x, dim=-1, p=2)\n",
    "    y =  torch.nn.functional.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(77)\n",
    "x=0.1 #currently set to use 10% of the labels for reduced label training \n",
    "onep=random.sample(range(0, len(X_train)), int(len(X_train)*x))\n",
    "all_img_names_train = [all_img_names[idx] for idx in onep]\n",
    "all_img_labels_ts_train = [all_img_labels_ts[idx] for idx in onep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(CFG, all_img_names_train,all_img_labels_ts_train, train_transform)\n",
    "valid_dataset = Dataset(CFG, all_img_names_valid, all_img_labels_val_ts, valid_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train SSL\n",
    "print('Training Cov-T')\n",
    "ssl_train_model(train_loader,model_vit,criterion_vit,optimizer_vit,scheduler_vit,model_cnn,criterion_cnn,optimizer_cnn,scheduler_cnn,num_epochs=100)\n",
    "#Saving SSL Models\n",
    "print('Saving Cov-T')\n",
    "torch.save(model_cnn,'./cass-r50-isic.pt')\n",
    "torch.save(model_vit,'./cass-r50-vit-isic.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn=torch.load('./covt-r50-isic.pt')\n",
    "model_vit=torch.load('./covt-r50-vit-isic.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Correspong Supervised CNN\n",
    "print('Fine tunning Cov-T')\n",
    "model_cnn.fc=nn.Linear(in_features=2048, out_features=8, bias=True)\n",
    "criterion = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)\n",
    "metric = MyF1Score(cfg)\n",
    "val_metric=MyF1Score(cfg)\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr = 3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=cfg.t_max,eta_min=cfg.min_lr,verbose=True)\n",
    "model_cnn.train()\n",
    "from torch.autograd import Variable\n",
    "best=0\n",
    "best_val=0\n",
    "last_loss=math.inf\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(50):\n",
    "    for images,label in train_loader:\n",
    "        model_cnn.train()\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "        model_cnn.to(device)\n",
    "        pred_ts=model_cnn(images)\n",
    "        loss = criterion(pred_ts, label)\n",
    "        score = metric(pred_ts, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "    train_score=metric.compute()\n",
    "    logs = {'train_loss': loss, 'Recall': train_score, 'lr': optimizer.param_groups[0]['lr']}\n",
    "    writer.add_scalar(\"Supervised-CNN Loss/train\", loss, epoch)\n",
    "    writer.add_scalar(\"Supervised-CNN Recall/train\", train_score, epoch)\n",
    "    for name, weight in model_cnn.named_parameters():\n",
    "        writer.add_histogram(name,weight, epoch)\n",
    "        writer.add_histogram(f'{name}.grad',weight.grad, epoch)\n",
    "    print(logs)\n",
    "    if best < train_score:\n",
    "        with torch.no_grad():\n",
    "        best=train_score\n",
    "        model_cnn.eval()\n",
    "        total_loss = 0\n",
    "        for images,label in valid_loader:\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            model_cnn.to(device)\n",
    "            pred_ts=model_cnn(images)\n",
    "            score_val = val_metric(pred_ts,label)\n",
    "            val_loss = criterion(pred_ts, label)\n",
    "            total_loss += val_loss.detach()\n",
    "        avg_loss=total_loss/ len(train_loader)   \n",
    "        print('Val Loss:',avg_loss)\n",
    "        val_score=val_metric.compute()\n",
    "        print('CNN Validation Score:',val_score)\n",
    "        writer.add_scalar(\"CNN Supervised F1/Validation\", val_score, epoch)\n",
    "        if avg_loss > last_loss:\n",
    "            counter+=1\n",
    "        else:\n",
    "            counter=0\n",
    "                \n",
    "        last_loss = avg_loss\n",
    "        if counter > 5:\n",
    "            print('Early Stopping!')\n",
    "            break\n",
    "        else:\n",
    "            if val_score > best_val:\n",
    "                best_val=val_score\n",
    "                print('Saving')\n",
    "                torch.save(model_cnn,\n",
    "                    './CASS-CNN-part-ft.pt')\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vit=torch.load('./covt-r50-vit-isic.pt')\n",
    "model_vit.head=nn.Linear(in_features=768, out_features=8, bias=True)\n",
    "criterion = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)\n",
    "metric = MyF1Score(cfg)\n",
    "optimizer = torch.optim.Adam(model_vit.parameters(), lr = 3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=cfg.t_max,eta_min=cfg.min_lr,verbose=True)\n",
    "model_vit.train()\n",
    "val_metric=MyF1Score(cfg)\n",
    "writer = SummaryWriter()\n",
    "from torch.autograd import Variable\n",
    "best=0\n",
    "best_val=0\n",
    "last_loss=math.inf\n",
    "for epoch in range(50):\n",
    "    for images,label in train_loader:\n",
    "        model_vit.train()\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "        model_vit.to(device)\n",
    "        pred_ts=model_vit(images)\n",
    "        loss = criterion(pred_ts, label)\n",
    "        score = metric(pred_ts,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "    train_score=metric.compute()\n",
    "    logs = {'train_loss': loss, 'Recall': train_score, 'lr': optimizer.param_groups[0]['lr']}\n",
    "    writer.add_scalar(\"Supervised-ViT Loss/train\", loss, epoch)\n",
    "    writer.add_scalar(\"Supervised-ViT Recall/train\", train_score, epoch)\n",
    "    for name, weight in model_vit.named_parameters():\n",
    "        writer.add_histogram(name,weight, epoch)\n",
    "        writer.add_histogram(f'{name}.grad',weight.grad, epoch)\n",
    "    print(logs)\n",
    "    if best < train_score:\n",
    "        with torch.no_grad():\n",
    "        best=train_score\n",
    "        model_cnn.eval()\n",
    "        total_loss = 0\n",
    "        for images,label in valid_loader:\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            model_cnn.to(device)\n",
    "            pred_ts=model_cnn(images)\n",
    "            score_val = val_metric(pred_ts,label)\n",
    "            val_loss = criterion(pred_ts, label)\n",
    "            total_loss += val_loss.detach()\n",
    "        avg_loss=total_loss/ len(train_loader)   \n",
    "        print('Val Loss:',avg_loss)\n",
    "        val_score=val_metric.compute()\n",
    "        print('CNN Validation Score:',val_score)\n",
    "        writer.add_scalar(\"CNN Supervised F1/Validation\", val_score, epoch)\n",
    "        if avg_loss > last_loss:\n",
    "            counter+=1\n",
    "        else:\n",
    "            counter=0\n",
    "                \n",
    "        last_loss = avg_loss\n",
    "        if counter > 5:\n",
    "            print('Early Stopping!')\n",
    "            break\n",
    "        else:\n",
    "            if val_score > best_val:\n",
    "                best_val=val_score\n",
    "                print('Saving')\n",
    "                torch.save(model_cnn,\n",
    "                    './CASS-ViT-part-ft.pt')\n",
    "writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps_env",
   "language": "python",
   "name": "ps_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}