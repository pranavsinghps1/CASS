{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import transforms as tsfm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torchcontrib.optim import SWA\n",
    "from torchmetrics import Metric\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # We dont need to give the path to CSV and images as medMNIST provides dataloaders out of hte box.\n",
    "    # Check MNIST Get-started-DEDL.ipynb for details on how to get the label to num, num to label and \n",
    "    # class weights for the MedMNIST dataset.\n",
    "    label_num2str = {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
    "    label_str2num = {'adipose': '0',\n",
    " 'background': '1',\n",
    " 'debris': '2',\n",
    " 'lymphocytes': '3',\n",
    " 'mucus': '4',\n",
    " 'smooth muscle': '5',\n",
    " 'normal colon mucosa': '6',\n",
    " 'cancer-associated stroma': '7',\n",
    " 'colorectal adenocarcinoma epithelium': '8'}\n",
    "    fl_alpha = 1.0  # alpha of focal_loss\n",
    "    fl_gamma = 2.0  # gamma of focal_loss\n",
    "    cls_weight =  [0.4368473694738948, 0.4597319463892779, 0.5959191838367675, 0.6024804960992198, 0.21920384076815363, 0.8874974994999001, 0.2, 0.4424484896979396, 1.0]\n",
    "    cnn_name='resnet50'\n",
    "    vit_name='vit_base_patch16_384'\n",
    "    seed = 77\n",
    "    num_classes = 4\n",
    "    batch_size = 16\n",
    "    t_max = 16\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    n_fold = 6\n",
    "    num_workers = 8\n",
    "    gpu_idx = 0\n",
    "    device = torch.device(f'cuda:{gpu_idx}' if torch.cuda.is_available() else 'cpu')\n",
    "    gpu_list = [gpu_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr, t_min, t_max):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = max(arr) - min(arr)\n",
    "    for i in arr:\n",
    "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr\n",
    "  \n",
    "# assign array and range\n",
    "array_1d = [1321,1457,1595,1339]\n",
    "range_to_normalize = (0.2, 1)\n",
    "normalized_array_1d = normalize(\n",
    "    array_1d, range_to_normalize[0], \n",
    "  range_to_normalize[1])\n",
    "  \n",
    "# display original and normalized array\n",
    "print(\"Original Array = \", array_1d)\n",
    "print(\"Normalized Array = \", normalized_array_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_everything(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define train & valid image transformation\n",
    "\"\"\"\n",
    "DATASET_IMAGE_MEAN = (0.485, 0.456, 0.406)\n",
    "DATASET_IMAGE_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = tsfm.Compose([tsfm.Resize((384,384)),\n",
    "                                tsfm.RandomApply([tsfm.ColorJitter(0.2, 0.2, 0.2),tsfm.RandomPerspective(distortion_scale=0.2),], p=0.3),\n",
    "                                tsfm.RandomApply([tsfm.RandomAffine(degrees=10),], p=0.3),\n",
    "                                tsfm.RandomVerticalFlip(p=0.3),\n",
    "                                tsfm.RandomHorizontalFlip(p=0.3),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])\n",
    "\n",
    "valid_transform = tsfm.Compose([tsfm.Resize((384,384)),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "import torch.utils.data as data\n",
    "\n",
    "data_flag = 'pathmnist'\n",
    "# data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
    "val_dataset = DataClass(split='val', transform=valid_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=valid_transform, download=download)\n",
    "\n",
    "pil_dataset = DataClass(split='train', download=download)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Focal-Loss\n",
    "\"\"\"\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    The focal loss for fighting against class-imbalance\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = 1e-12  # prevent training from Nan-loss error\n",
    "        self.cls_weights = torch.tensor([CFG.cls_weight],dtype=torch.float, requires_grad=False, device=CFG.device)\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits & target should be tensors with shape [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(logits)\n",
    "        one_subtract_probs = 1.0 - probs\n",
    "        # add epsilon\n",
    "        probs_new = probs + self.epsilon\n",
    "        one_subtract_probs_new = one_subtract_probs + self.epsilon\n",
    "        # calculate focal loss\n",
    "        log_pt = target * torch.log(probs_new) + (1.0 - target) * torch.log(one_subtract_probs_new)\n",
    "        pt = torch.exp(log_pt)\n",
    "        focal_loss = -1.0 * (self.alpha * (1 - pt) ** self.gamma) * log_pt\n",
    "        focal_loss = focal_loss * self.cls_weights\n",
    "        return torch.mean(focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define F1 score metric\n",
    "\"\"\"\n",
    "class MyF1Score(Metric):\n",
    "    def __init__(self, cfg, threshold: float = 0.5, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.cfg = cfg\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"tp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fn\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        assert preds.shape == target.shape\n",
    "        preds_str_batch = self.num_to_str(torch.sigmoid(preds))\n",
    "        target_str_batch = self.num_to_str(target)\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for pred_str_list, target_str_list in zip(preds_str_batch, target_str_batch):\n",
    "            for pred_str in pred_str_list:\n",
    "                if pred_str in target_str_list:\n",
    "                    tp += 1\n",
    "                if pred_str not in target_str_list:\n",
    "                    fp += 1\n",
    "\n",
    "            for target_str in target_str_list:\n",
    "                if target_str not in pred_str_list:\n",
    "                    fn += 1\n",
    "        self.tp += tp\n",
    "        self.fp += fp\n",
    "        self.fn += fn\n",
    "\n",
    "    def compute(self):\n",
    "        f1 = 2.0 * self.tp / (2.0 * self.tp + self.fn + self.fp)\n",
    "        return f1\n",
    "    \n",
    "    def num_to_str(self, ts: torch.Tensor) -> list:\n",
    "        batch_bool_list = (ts > self.threshold).detach().cpu().numpy().tolist()\n",
    "        batch_str_list = []\n",
    "        for one_sample_bool in batch_bool_list:\n",
    "            lb_str_list = [self.cfg.label_num2str[lb_idx] for lb_idx, bool_val in enumerate(one_sample_bool) if bool_val]\n",
    "            if len(lb_str_list) == 0:\n",
    "                lb_str_list = ['healthy']\n",
    "            batch_str_list.append(lb_str_list)\n",
    "        return batch_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "cfg=CFG()\n",
    "model_cnn = timm.create_model(cfg.cnn_name, pretrained=True)\n",
    "model_vit = timm.create_model(cfg.vit_name, pretrained=True)\n",
    "model_cnn.to(device)\n",
    "model_vit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssl_train_model(train_loader,model_vit,criterion_vit,optimizer_vit,scheduler_vit,model_cnn,criterion_cnn,optimizer_cnn,scheduler_cnn,num_epochs):\n",
    "    writer = SummaryWriter()\n",
    "    phase = 'train'\n",
    "    model_cnn.train()\n",
    "    model_vit.train()\n",
    "    f1_score_cnn=0\n",
    "    f1_score_vit=0\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            for img,_ in tqdm(train_loader):\n",
    "                f1_score_cnn=0\n",
    "                f1_score_vit=0\n",
    "                img = img.to(device)\n",
    "                pred_vit = model_vit(img)\n",
    "                pred_cnn = model_cnn(img)\n",
    "                model_sim_loss=loss_fn(pred_vit,pred_cnn)\n",
    "                loss = model_sim_loss.mean()\n",
    "                loss.backward()\n",
    "                optimizer_cnn.step()\n",
    "                optimizer_vit.step()\n",
    "                scheduler_cnn.step()\n",
    "                scheduler_vit.step()\n",
    "            print('For -',i,'Loss:',loss) \n",
    "            writer.add_scalar(\"Self-Supervised Loss/train\", loss, i)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cnn = SWA(torch.optim.Adam(model_cnn.parameters(), lr= 1e-3))\n",
    "optimizer_vit = SWA(torch.optim.Adam(model_vit.parameters(), lr= 1e-3))\n",
    "scheduler_cnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_cnn,\n",
    "                                                                    T_max=16,\n",
    "                                                                    eta_min=1e-6)\n",
    "scheduler_vit = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_vit,\n",
    "                                                                    T_max=16,\n",
    "                                                                    eta_min=1e-6)\n",
    "\n",
    "\n",
    "fl_alpha = 1.0  # alpha of focal_loss\n",
    "fl_gamma = 2.0  # gamma of focal_loss\n",
    "cls_weight = [0.9475164011246484, 0.4934395501405811, 0.5029053420805999, 0.2, 1.0]\n",
    "criterion_vit = FocalLoss(fl_alpha, fl_gamma)\n",
    "criterion_cnn = FocalLoss(fl_alpha, fl_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    x =  torch.nn.functional.normalize(x, dim=-1, p=2)\n",
    "    y =  torch.nn.functional.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_train_model(train_loader,model_vit,criterion_vit,optimizer_vit,scheduler_vit,model_cnn,criterion_cnn,optimizer_cnn,scheduler_cnn,num_epochs=1)\n",
    "    #Saving SSL Models\n",
    "print('Saving Cov-T')\n",
    "    \n",
    "torch.save(model_cnn,'./cass-r50-med-mnist-pathmnist.pt')\n",
    "torch.save(model_vit,'./cass-vit-med-mnist-pathmnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx, (train_indices, valid_indices) in enumerate(k_fold.split(all_img_names)):\n",
    "model_vit=torch.load('./cass-vit-med-mnist-pathmnist.pt')\n",
    "model_cnn=torch.load('./cass-r50-med-mnist-pathmnist.pt')\n",
    "last_loss=math.inf\n",
    "val_loss_arr=[]\n",
    "train_loss_arr=[]\n",
    "counter=0\n",
    "    \n",
    "model_cnn.to(device)\n",
    "model_vit.to(device)\n",
    "print('*'*10)\n",
    "\n",
    "    \n",
    "#Train Correspong Supervised CNN\n",
    "print('Fine tunning Cov-T')\n",
    "writer = SummaryWriter()\n",
    "model_cnn.fc=nn.Linear(in_features=2048, out_features=4, bias=True)\n",
    "criterion = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)\n",
    "metric = MyF1Score(cfg)\n",
    "val_metric=MyF1Score(cfg)\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr = 3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=cfg.t_max,eta_min=cfg.min_lr)\n",
    "model_cnn.train()\n",
    "from torch.autograd import Variable\n",
    "best=0\n",
    "best_val=0\n",
    "for epoch in tqdm(range(50)):\n",
    "    total_loss = 0\n",
    "    for images,label in train_loader:\n",
    "        model_cnn.train()\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "        model_cnn.to(device)\n",
    "        pred_ts=model_cnn(images)\n",
    "        loss = criterion(pred_ts, label)\n",
    "        score = metric(pred_ts,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.detach()\n",
    "    avg_loss=total_loss/ len(train_loader)\n",
    "    train_score=metric.compute()\n",
    "    logs = {'train_loss': avg_loss, 'train_f1': train_score, 'lr': optimizer.param_groups[0]['lr']}\n",
    "    writer.add_scalar(\"CNN Supervised Loss/train\", loss, epoch)\n",
    "    writer.add_scalar(\"CNN Supervised F1/train\", train_score, epoch)\n",
    "    print(logs)\n",
    "    if best < train_score:\n",
    "        best=train_score\n",
    "        model_cnn.eval()\n",
    "        total_loss = 0\n",
    "        for images,label in valid_loader:\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            model_cnn.to(device)\n",
    "            pred_ts=model_cnn(images)\n",
    "            score_val = val_metric(pred_ts,label)\n",
    "            val_loss = criterion(pred_ts, label)\n",
    "            total_loss += val_loss.detach()\n",
    "        avg_loss=total_loss/ len(train_loader)   \n",
    "        print('Val Loss:',avg_loss)\n",
    "        val_score=val_metric.compute()\n",
    "        print('CNN Validation Score:',val_score)\n",
    "        writer.add_scalar(\"CNN Supervised F1/Validation\", val_score, epoch)\n",
    "        if avg_loss > last_loss:\n",
    "            counter+=1\n",
    "        else:\n",
    "            counter=0\n",
    "                \n",
    "        last_loss = avg_loss\n",
    "        if counter > 5:\n",
    "            print('Early Stopping!')\n",
    "            break\n",
    "        else:\n",
    "            if val_score > best_val:\n",
    "                best_val=val_score\n",
    "                print('Saving')\n",
    "                torch.save(model_cnn,\n",
    "                    './cass-r50-med-mnist-pathmnist-label.pt')\n",
    "writer.flush()\n",
    "last_loss=999999999\n",
    "val_loss_arr=[]\n",
    "train_loss_arr=[]\n",
    "counter=0\n",
    "# Training the Corresponding ViT\n",
    "model_vit.head=nn.Linear(in_features=768, out_features=4, bias=True)\n",
    "criterion = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)\n",
    "metric = MyF1Score(cfg)\n",
    "optimizer = torch.optim.Adam(model_vit.parameters(), lr = 3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=cfg.t_max,eta_min=cfg.min_lr)\n",
    "model_vit.train()\n",
    "val_metric=MyF1Score(cfg)\n",
    "writer = SummaryWriter()\n",
    "from torch.autograd import Variable\n",
    "best=0\n",
    "best_val=0\n",
    "for epoch in tqdm(range(50)):\n",
    "    total_loss = 0\n",
    "    for images,label in train_loader:\n",
    "        model_vit.train()\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "        model_vit.to(device)\n",
    "        pred_ts=model_vit(images)\n",
    "        loss = criterion(pred_ts, label)\n",
    "        score = metric(pred_ts,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.detach()\n",
    "    avg_loss=total_loss/ len(train_loader)\n",
    "    train_score=metric.compute()\n",
    "    logs = {'train_loss': loss, 'train_f1': train_score, 'lr': optimizer.param_groups[0]['lr']}\n",
    "    writer.add_scalar(\"ViT Supervised Loss/train\", loss, epoch)\n",
    "    writer.add_scalar(\"ViT Supervised F1/train\", train_score, epoch)\n",
    "    print(logs)\n",
    "    if best < train_score:\n",
    "        best=train_score\n",
    "        model_vit.eval()\n",
    "        total_loss = 0\n",
    "        for images,label in valid_loader:\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            model_vit.to(device)\n",
    "            pred_ts=model_vit(images)\n",
    "            score_val = val_metric(pred_ts,label)\n",
    "            val_loss = criterion(pred_ts, label)\n",
    "            total_loss += val_loss.detach()\n",
    "        avg_loss=total_loss/ len(train_loader)\n",
    "        val_score=val_metric.compute()\n",
    "        print('ViT Validation Score:',val_score)\n",
    "        print('Val Loss:',avg_loss)\n",
    "        writer.add_scalar(\"ViT Supervised F1/Validation\", val_score, epoch)\n",
    "        if avg_loss > last_loss:\n",
    "            counter+=1\n",
    "        else:\n",
    "            counter=0\n",
    "                \n",
    "        last_loss = avg_loss\n",
    "        if counter > 5:\n",
    "            print('Early Stopping!')\n",
    "            break\n",
    "        else:\n",
    "            if val_score > best_val:\n",
    "                best_val=val_score\n",
    "                print('Saving')\n",
    "                torch.save(model_vit,\n",
    "                                   './cass-vit-med-mnist-pathmnist.pt')\n",
    "                        \n",
    "    writer.flush()                \n",
    "    print('*'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps_env",
   "language": "python",
   "name": "ps_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
